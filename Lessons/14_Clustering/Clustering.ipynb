{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "def graph_kmeans(data, means, assignments):\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(means)))\n",
    "    data = np.array(data)\n",
    "    assignments = np.array(assignments)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "    \n",
    "    # temp plot to get limits\n",
    "    ax.plot(*zip(*data), color='k', marker='o', markersize=5, linestyle='None')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    \n",
    "\n",
    "    if len(assignments):\n",
    "        ax.lines.pop()\n",
    "        if len(means) > 2:\n",
    "            voronoi_plot_2d(Voronoi(means), ax=ax, show_vertices=False, show_points=False)\n",
    "    for i, pnt in enumerate(means):\n",
    "        clr = colors[i]\n",
    "        ax.plot(*pnt, color=clr, marker='*', markersize=10, linestyle='None')\n",
    "        ax.plot(*zip(*data[assignments == i]), color=clr, marker='o', markersize=5, linestyle='None')\n",
    "\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_ylim(*ylim)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is copied and adapted from https://github.com/joelgrus/data-science-from-scratch/blob/master/code-python3/clustering.py, the github repository for the book “Data Science from Scratch by Joel Grus (O’Reilly). Copyright 2015 Joel Grus, 978-1-4919-0142-7.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from linear_algebra import squared_distance, vector_mean, distance\n",
    "import math, random\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class KMeans:\n",
    "    \"\"\"performs k-means clustering\"\"\"\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k = k          # number of clusters\n",
    "        self.means = None   # means of clusters\n",
    "\n",
    "    def classify(self, input):\n",
    "        \"\"\"return the index of the cluster closest to the input\"\"\"\n",
    "        return min(range(self.k),\n",
    "                   key=lambda i: squared_distance(input, self.means[i]))\n",
    "\n",
    "    def train(self, inputs, plot=True):\n",
    "\n",
    "        self.means = random.sample(inputs, self.k)\n",
    "        assignments = []\n",
    "        if plot:\n",
    "            fig = graph_kmeans(inputs, self.means, assignments)\n",
    "            fig.suptitle(\"k={}, iteration={}\".format(self.k, 0))\n",
    "            fig.savefig(\"kmeans_k{}iter{}.png\".format(self.k, 0))\n",
    "            plt.close()\n",
    "        iteration = 1\n",
    "\n",
    "        while True:\n",
    "            # Find new assignments\n",
    "            new_assignments = list(map(self.classify, inputs))\n",
    "            if plot:\n",
    "                fig = graph_kmeans(inputs, self.means, new_assignments)\n",
    "                fig.suptitle(\"k={}, iteration={}\".format(self.k, iteration))\n",
    "                fig.savefig(\"kmeans_k{}iter{}.png\".format(self.k, iteration))\n",
    "                plt.close()\n",
    "            \n",
    "            # If no assignments have changed, we're done.\n",
    "            if assignments == new_assignments:\n",
    "                return assignments\n",
    "\n",
    "            # Otherwise keep the new assignments,\n",
    "            assignments = new_assignments\n",
    "\n",
    "            for i in range(self.k):\n",
    "                i_points = [p for p, a in zip(inputs, assignments) if a == i]\n",
    "                # avoid divide-by-zero if i_points is empty\n",
    "                if i_points:\n",
    "                    self.means[i] = vector_mean(i_points)\n",
    "            iteration += 1\n",
    "\n",
    "def squared_clustering_errors(inputs, k, plot=False):\n",
    "    \"\"\"finds the total squared error from k-means clustering the inputs\"\"\"\n",
    "    clusterer = KMeans(k)\n",
    "    clusterer.train(inputs, plot)\n",
    "    means = clusterer.means\n",
    "    assignments = list(map(clusterer.classify, inputs))\n",
    "\n",
    "    return sum(squared_distance(input,means[cluster])\n",
    "               for input, cluster in zip(inputs, assignments))\n",
    "\n",
    "def plot_squared_clustering_errors(scatterplot=False):\n",
    "\n",
    "    ks = range(1, len(inputs) + 1)\n",
    "    errors = [squared_clustering_errors(inputs, k, scatterplot) for k in ks]\n",
    "\n",
    "    plt.plot(ks, errors)\n",
    "    plt.xticks(ks)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"total squared error\")\n",
    "    plt.show()\n",
    "\n",
    "def run_kmeans(inputs, plot=False):\n",
    "\n",
    "\n",
    "    random.seed(0) # so you get the same results as me\n",
    "    clusterer = KMeans(3)\n",
    "    clusterer.train(inputs, plot)\n",
    "    print(\"3-means:\")\n",
    "    print(clusterer.means)\n",
    "    print()\n",
    "\n",
    "    random.seed(0)\n",
    "    clusterer = KMeans(2)\n",
    "    clusterer.train(inputs, plot)\n",
    "    print(\"2-means:\")\n",
    "    print(clusterer.means)\n",
    "    print()\n",
    "\n",
    "    errors = [(k, squared_clustering_errors(inputs, k)) for k in range(1, min(len(inputs) + 1, 20))]\n",
    "    plt.plot(*zip(*errors))\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"J\")\n",
    "       \n",
    "        \n",
    "#\n",
    "# hierarchical clustering\n",
    "#\n",
    "\n",
    "def is_leaf(cluster):\n",
    "    \"\"\"a cluster is a leaf if it has length 1\"\"\"\n",
    "    return len(cluster) == 1\n",
    "\n",
    "def get_children(cluster):\n",
    "    \"\"\"returns the two children of this cluster if it's a merged cluster;\n",
    "    raises an exception if this is a leaf cluster\"\"\"\n",
    "    if is_leaf(cluster):\n",
    "        raise TypeError(\"a leaf cluster has no children\")\n",
    "    else:\n",
    "        return cluster[1]\n",
    "\n",
    "def get_values(cluster):\n",
    "    \"\"\"returns the value in this cluster (if it's a leaf cluster)\n",
    "    or all the values in the leaf clusters below it (if it's not)\"\"\"\n",
    "    if is_leaf(cluster):\n",
    "        return cluster # is already a 1-tuple containing value\n",
    "    else:\n",
    "        return [value\n",
    "                for child in get_children(cluster)\n",
    "                for value in get_values(child)]\n",
    "\n",
    "def cluster_distance(cluster1, cluster2, distance_agg=min):\n",
    "    \"\"\"finds the aggregate distance between elements of cluster1\n",
    "    and elements of cluster2\"\"\"\n",
    "    return distance_agg([distance(input1, input2)\n",
    "                        for input1 in get_values(cluster1)\n",
    "                        for input2 in get_values(cluster2)])\n",
    "\n",
    "def get_merge_order(cluster):\n",
    "    if is_leaf(cluster):\n",
    "        return float('inf')\n",
    "    else:\n",
    "        return cluster[0] # merge_order is first element of 2-tuple\n",
    "\n",
    "def bottom_up_cluster(inputs, distance_agg=min):\n",
    "    # start with every input a leaf cluster / 1-tuple\n",
    "    clusters = [(input,) for input in inputs]\n",
    "\n",
    "    # as long as we have more than one cluster left...\n",
    "    while len(clusters) > 1:\n",
    "        # find the two closest clusters\n",
    "        c1, c2 = min([(cluster1, cluster2)\n",
    "                     for i, cluster1 in enumerate(clusters)\n",
    "                     for cluster2 in clusters[:i]],\n",
    "                     key=lambda p: cluster_distance(p[0], p[1], distance_agg))\n",
    "\n",
    "        # remove them from the list of clusters\n",
    "        clusters = [c for c in clusters if c != c1 and c != c2]\n",
    "\n",
    "        # merge them, using merge_order = # of clusters left\n",
    "        merged_cluster = (len(clusters), [c1, c2])\n",
    "\n",
    "        # and add their merge\n",
    "        clusters.append(merged_cluster)\n",
    "\n",
    "    # when there's only one cluster left, return it\n",
    "    return clusters[0]\n",
    "\n",
    "\n",
    "def generate_clusters(base_cluster, num_clusters):\n",
    "    # start with a list with just the base cluster\n",
    "    clusters = [base_cluster]\n",
    "\n",
    "    # as long as we don't have enough clusters yet...\n",
    "    while len(clusters) < num_clusters:\n",
    "        # choose the last-merged of our clusters\n",
    "        next_cluster = min(clusters, key=get_merge_order)\n",
    "        # remove it from the list\n",
    "        clusters = [c for c in clusters if c != next_cluster]\n",
    "        # and add its children to the list (i.e., unmerge it)\n",
    "        clusters.extend(get_children(next_cluster))\n",
    "\n",
    "    # once we have enough clusters...\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Science From Scratch example\n",
    "# Cluster graphs will be saved to current working directory\n",
    "run_kmeans(inputs = [[-14,-5],[13,13],[20,23],[-19,-11],[-9,-16],[21,27],[-49,15],[26,13],[-46,5],[-34,-1],[11,15],[-49,0],[-22,-16],[19,28],[-12,-8],[-13,-19],[-41,8],[-11,-6],[-25,-9],[-18,-3]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Portland public art example\n",
    "# Note that cluster graphs will overwrite those produced above - move them to another directory to save\n",
    "art = pd.read_excel(\"public_art.xlsx\").dropna()\n",
    "inputs = [ tuple(x) for x in art[[\"lng\", \"lat\"]].values ]\n",
    "run_kmeans(inputs, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot of public art locations\n",
    "art.plot(\"lng\", \"lat\", \"scatter\", figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot of data science from scratch example\n",
    "inputs = [[-14,-5],[13,13],[20,23],[-19,-11],[-9,-16],[21,27],[-49,15],[26,13],[-46,5],[-34,-1],[11,15],[-49,0],[-22,-16],[19,28],[-12,-8],[-13,-19],[-41,8],[-11,-6],[-25,-9],[-18,-3]]\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(*zip(*inputs))\n",
    "for label, (x,y) in enumerate(inputs):\n",
    "    ax.annotate(label, xy=(x,y), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data science from scratch example\n",
    "inputs = np.array([[-14,-5],[13,13],[20,23],[-19,-11],[-9,-16],[21,27],[-49,15],[26,13],[-46,5],[-34,-1],[11,15],[-49,0],\n",
    "                   [-22,-16],[19,28],[-12,-8],[-13,-19],[-41,8],[-11,-6],[-25,-9],[-18,-3]])\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "clusterlinkage = linkage(inputs)\n",
    "\n",
    "# dendrogram\n",
    "dn = dendrogram(clusterlinkage, ax=ax)\n",
    "ax.set_xlabel(\"data point index\")\n",
    "ax.set_ylabel(\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "fig, axes = plt.subplots(6, 3, figsize=(16,30))\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "markers = ['o', '*', 'x']\n",
    "colmark = [(c, m) for c in colors for m in markers]\n",
    "for n_clusters in range(2,len(inputs)):\n",
    "    cluster_identity = fcluster(clusterlinkage, n_clusters, 'maxclust')\n",
    "    for c in range(1, n_clusters+1):\n",
    "        cluster = inputs[cluster_identity == c]\n",
    "        ax = axes.flatten()[n_clusters-2]\n",
    "        ax.plot(*zip(*cluster), marker=colmark[c][1], linestyle='None', color=colmark[c][0])\n",
    "        ax.set_title(\"{} Clusters\".format(n_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
